<!DOCTYPE html><html lang="en" data-theme="light"><head><script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">window.dojoRequire(["mojo/signup-forms/Loader"],function(o){o.start({baseUrl:"mc.us4.list-manage.com",uuid:"1fd8b3cd2ba70f51528f758b7",lid:"0a5bf38afd",uniqueMethods:!0})})</script><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Graph Neural Networks for link predictions | Research @ WDSS</title><meta name="description" content="Or yet in wise old Ravenclaw,  If you have a ready mind,  Where those of wit and learning,  Will always find their kind."><meta name="keywords" content="machine learning,predictions,graph neural networks"><meta name="author" content="Warwick Data Science"><meta name="copyright" content="Warwick Data Science"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Graph Neural Networks for link predictions"><meta name="twitter:description" content="Or yet in wise old Ravenclaw,  If you have a ready mind,  Where those of wit and learning,  Will always find their kind."><meta name="twitter:image" content="https://research.wdss.io/banners/social-network.jpg"><meta property="og:type" content="article"><meta property="og:title" content="Graph Neural Networks for link predictions"><meta property="og:url" content="https://research.wdss.io/link-predictions/"><meta property="og:site_name" content="Research @ WDSS"><meta property="og:description" content="Or yet in wise old Ravenclaw,  If you have a ready mind,  Where those of wit and learning,  Will always find their kind."><meta property="og:image" content="https://research.wdss.io/banners/social-network.jpg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode="1",t=Cookies.get("theme");if("1"==autoChangeMode){var isDarkMode=window.matchMedia("(prefers-color-scheme: dark)").matches,isLightMode=window.matchMedia("(prefers-color-scheme: light)").matches,isNotSpecified=window.matchMedia("(prefers-color-scheme: no-preference)").matches,hasNoSupport=!isDarkMode&&!isLightMode&&!isNotSpecified;if(void 0===t){if(isLightMode)activateLightMode();else if(isDarkMode)activateDarkMode();else if(isNotSpecified||hasNoSupport){console.log("You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.");var now=new Date,hour=now.getHours(),isNight=hour<6||18<=hour;isNight?activateDarkMode():activateLightMode()}}else"light"==t?activateLightMode():activateDarkMode()}else"2"==autoChangeMode?(isNight=(hour=(now=new Date).getHours())<6||18<=hour,void 0===t?isNight?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode()):"dark"==t?activateDarkMode():"light"==t&&activateLightMode();function activateDarkMode(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#000")}function activateLightMode(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#fff")}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://research.wdss.io/link-predictions/"><link rel="next" title="Store Sales - Time Series Forecasting Challenge" href="https://research.wdss.io/sales-forecasting-challenge/"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"4718922828481704",enable_page_level_ads:"true"})</script><script data-ad-client="ca-pub-4718922828481704" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"We didn't find any results for: ${query}"}},translate:void 0,copy:{success:"Copied successfully",error:"Copy failed",noSupport:"Not supported by browser"},bookmark:{message_prev:"Press",message_next:"to bookmark this page"},runtime_unit:"days",runtime:!0,copyright:void 0,ClickShowText:void 0,medium_zoom:!1,fancybox:!0,Snackbar:{bookmark:{message_prev:"Press",message_next:"to bookmark this page"},chs_to_cht:"Traditional Chinese Activated Manually",cht_to_chs:"Simplified Chinese Activated Manually",day_to_night:"Dark Mode Activated Manually",night_to_day:"Light Mode Activated Manually",bgLight:"#49b1f5",bgDark:"#2d3035",position:"bottom-left"},baiduPush:!1,highlightCopy:!0,highlightLang:!0,highlightShrink:"false",isFontAwesomeV5:!1,isPhotoFigcaption:!1}</script><script>var GLOBAL_CONFIG_SITE={isPost:!0,isHome:!1,isSidebar:!0}</script><noscript><style>#page-header{opacity:1}.justified-gallery img{opacity:1}</style></noscript><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Research @ WDSS" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">22</div></a></div></div><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">36</div></a></div></div><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">23</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Contents</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Graphs-A-Brief-Introduction"><span class="toc-number">1.1.</span> <span class="toc-text">Graphs: A Brief Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Datasets"><span class="toc-number">1.2.</span> <span class="toc-text">Datasets</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#"><span class="toc-number">2.</span> <span class="toc-text">Basic Analysis of Datasets</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#"><span class="toc-number">3.</span> <span class="toc-text">Temporal Email Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Centrality-Analyses"><span class="toc-number">3.1.</span> <span class="toc-text">Centrality Analyses</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Link-Prediction"><span class="toc-number">3.2.</span> <span class="toc-text">Link Prediction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Construct-splits-of-the-input-data"><span class="toc-number">3.2.1.</span> <span class="toc-text">Construct splits of the input data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Train-and-validate-the-link-prediction-model"><span class="toc-number">3.2.2.</span> <span class="toc-text">Train and validate the link prediction model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluate-the-best-model-using-the-test-set"><span class="toc-number">3.2.3.</span> <span class="toc-text">Evaluate the best model using the test set</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#"><span class="toc-number">4.</span> <span class="toc-text">Further Research</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image:url(/banners/social-network.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Research @ WDSS</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Graph Neural Networks for link predictions</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2022-03-20 00:00:00"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2022-03-20</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2022-03-20 00:00:00"><i class="fa fa-history" aria-hidden="true"></i> Updated 2022-03-20</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><a class="post-meta__categories" href="https://www.linkedin.com/in/kah-long-ng-6b10b81b9/" target="_blank" rel="noopener">Kah Long Ng</a><span>, </span><a class="post-meta__categories" href="https://www.linkedin.com/in/peter-hyland-53a2951ba/" target="_blank" rel="noopener">Peter Hyland</a></span><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Social-Sciences/">Social Sciences</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Social-Sciences/Sociology/">Sociology</a></span></div><div class="meta-secondline"><span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>Word count:</span><span class="word-count">2.9k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>Reading time: 18 min</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span></span><span class="post-meta-commentcount"><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>Comments:</span><span class="disqus-comment-count comment-count"><a href="https://research.wdss.io/link-predictions/#disqus_thread"></a></span></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><h1>Introduction</h1><p>“Or yet in wise old Ravenclaw,<br>If you have a ready mind,<br>Where those of wit and learning,<br>Will always find their kind.”</p><p>But what exactly is one’s kind? How does Facebook recommend you friends? True to Ravenclaw tradition, our query led to this project, which delved into applying machine learning algorithms to the task of predicting graph connections.</p><h2 id="Graphs-A-Brief-Introduction">Graphs: A Brief Introduction</h2><p>A graph in the sense of this project is very different to the type of graph that is used to describe the relationship between two variables (i.e. two axes, dependent and independent variable). This project concerns the mathematical definition of a graph which is a structure indicating the connections between a set of objects.</p><p>This <strong>graph</strong> is defined as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>V</mi><mo separator="true">,</mo><mi>E</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(V,E)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.22222em">V</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mclose">)</span></span></span></span> where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span></span></span></span> is a set of vertices representing the objects in question, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>E</mi></mrow><annotation encoding="application/x-tex">E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.05764em">E</span></span></span></span> is a set of pairs <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mclose">)</span></span></span></span> with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo>∈</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">u, v \in V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7335400000000001em;vertical-align:-.19444em"></span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.22222em">V</span></span></span></span> of vertices indicating the connections or “edges” between the vertices. Vertices are also often referred to as “nodes” as well.</p><p>In an edge set, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mclose">)</span></span></span></span> is considered the same as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><mi>u</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(v,u)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal">u</span><span class="mclose">)</span></span></span></span>, the graph is called undirected and the graph is considered directed if they are different, the nomenclature indicating the usage of directed graphs in representing problems where there is a sense of “directions” between vertices.</p><p>Imagine you’re on Tinder: nodes are people like you, and edges are lines connecting people (the nodes) together. Edges can be directed (two-way) or undirected (one-way). In the Tinder example, directed may mean both have swiped on each other while undirected may point to a single-sided affair.</p><p>Graphs also can have other parameters (in this project, we study <strong>temporal graphs</strong> which have a time parameter over which the connections vary).</p><p>They are often used to represent situations as they are a good analogy for connections between locations by roads, flight paths, and other modes of transport or the connections establised in human communication. They have extensive applications in data science as questions that concern connections of any kind or flows through structures can easily be represented with graphs.</p><p>This project is made specific to graphs based on the usage of concepts reletated inherently to the representation of the data by a graph in the machine learning methodology. We define these briefly here. A <strong>path</strong> is a collection of distinct edges <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>e</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>e</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>e</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(e_1,e_2,...,e_{n-1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.301108em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> such that there is a sequence of nodes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(v_1,...,v_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> such that <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>e</mi><mi>i</mi></msub><mo>=</mo><mo stretchy="false">(</mo><msub><mi>v</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>v</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">e_i = (v_i, v_{i+1})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.31166399999999994em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.311664em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.208331em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> and we call the length of the path the number of edges in it. Furthermore, <strong>connected component</strong> is a subset of the vertices such that, for any two vertices in the set, there is a path with those vertices as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">v_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>v</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">v_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>. In addition, the <strong>degree</strong> of a node is the number of edges it is an element of, and its degree centrality is the same as the degree. The <strong>distance</strong> between two nodes <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">d(u,v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal">d</span><span class="mopen">(</span><span class="mord mathnormal">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mclose">)</span></span></span></span> is the length of the shortest path between them with the distance being conventionally infinite if there is no such path.</p><h2 id="Datasets">Datasets</h2><p>This project utilises two graph datasets that arise from real world situations. They were sourced from <a href="https://snap.stanford.edu/data/" target="_blank" rel="noopener">the Stanford Large Network Dataset Collection</a>. The first is the Google Plus dataset that represents connections between users of the Google Plus social network. The second is a dataset representing emails sent between employees of a large European Research Institution. This is a temporal dataset (times at which emails were sent were recorded). While it is split between 4 departments, we have decided to analyze them in totality.</p><p>To those who don’t know, Google+ was a social networking site that was created in 2011 before it was closed in April 2019. It had a feature called <em>share circle</em> which allowed users to share their network data, including node features, circles, and ego networks. The ego networks are formed by each node’s connections and the features indclude data about each person that is sufficent for for some analyses but for the dataset to also remain anonymised.</p><p>In our analysis we make use of the <a href="https://networkx.org/documentation/stable" target="_blank" rel="noopener">NetworkX</a> Python package to transoform the edge list data frame into a Python Graph object.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Email Dataset</span></span><br><span class="line"><span class="comment"># Reading Edges Text File into List</span></span><br><span class="line">edges = []</span><br><span class="line"><span class="keyword">with</span> open(path) <span class="keyword">as</span> f:</span><br><span class="line">     <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        line = line.strip()</span><br><span class="line">        <span class="keyword">if</span> line != <span class="string">''</span>:</span><br><span class="line">            edges.append(line)</span><br><span class="line">            </span><br><span class="line"><span class="comment"># Reading Edges Text File into Dataframe</span></span><br><span class="line">e_df = pd.read_csv(path, delim_whitespace=<span class="literal">True</span>, </span><br><span class="line">                   names=[<span class="string">'Source'</span>, <span class="string">'Destination'</span>, <span class="string">'Time'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reading Edges List into Graph</span></span><br><span class="line">new_df = e_df.drop(columns=[<span class="string">'Time'</span>])</span><br><span class="line">e_graph = nx.from_pandas_edgelist(new_df, <span class="string">'Source'</span>, <span class="string">'Destination'</span>)</span><br><span class="line">e_df.head()</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>Source</th><th>Destination</th><th>Time</th></tr></thead><tbody><tr><th>0</th><td>582</td><td>364</td><td>0</td></tr><tr><th>1</th><td>168</td><td>472</td><td>2797</td></tr><tr><th>2</th><td>168</td><td>912</td><td>3304</td></tr><tr><th>3</th><td>2</td><td>790</td><td>4523</td></tr><tr><th>4</th><td>2</td><td>322</td><td>7926</td></tr></tbody></table><h1>Basic Analysis of Datasets</h1><p>The Google Plus Dataset (G+) is significantly bigger than that of the university email network with 109 times the number of nodes. The average node degree of both datasets (33, 227) differ much more than their median degree (22, 42)—meaning that G+ has a select few with just too many edge connections.</p><p>For our further analysis we will focus only on the email data set. G+ dataset turned out to be too computationally expensive and a rather sparse network. Choosing a random subset of a graph-type data set brings its own complications.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Summay of the data</span></span><br><span class="line">e_degree = pd.DataFrame(</span><br><span class="line">    e_graph.degree(), columns = [<span class="string">'node'</span>, <span class="string">'Email node degree'</span>]</span><br><span class="line">).set_index(<span class="string">'node'</span>).describe()</span><br><span class="line"></span><br><span class="line">g_degree = pd.DataFrame(</span><br><span class="line">    g_graph.degree(), columns = [<span class="string">'node'</span>, <span class="string">'G+ node degree'</span>]</span><br><span class="line">).set_index(<span class="string">'node'</span>).describe()</span><br><span class="line"></span><br><span class="line">summary_df = pd.concat([e_degree, g_degree], axis=<span class="number">1</span>).astype(<span class="string">'int'</span>)</span><br><span class="line">summary_df</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>Email node degree</th><th>G+ node degree</th></tr></thead><tbody><tr><th>count</th><td>986</td><td>107614</td></tr><tr><th>mean</th><td>32</td><td>227</td></tr><tr><th>std</th><td>37</td><td>581</td></tr><tr><th>min</th><td>1</td><td>1</td></tr><tr><th>25%</th><td>6</td><td>11</td></tr><tr><th>50%</th><td>22</td><td>42</td></tr><tr><th>75%</th><td>44</td><td>170</td></tr><tr><th>max</th><td>345</td><td>20127</td></tr></tbody></table><h1>Temporal Email Dataset</h1><p>The total duration of the temporal dataset is 17 months. Divided into 6 periods of approximately 3 months each, we find that each period consists roughly the same amount of nodes and edges (around 800 nodes and 6300 edges)—email frequency was stable throughout.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set the breaks between the time periods</span></span><br><span class="line">breaks = np.linspace(<span class="number">0</span>, <span class="number">45405138</span>, <span class="number">7</span>).astype(<span class="string">'int'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a dictionary of subgraphs for each time period</span></span><br><span class="line">subgraph = dict()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    subgraph[i] = nx.from_pandas_edgelist(</span><br><span class="line">        e_df[(e_df.Time &gt;= breaks[i]) &amp; (e_df.Time &lt; breaks[i + <span class="number">1</span>])], </span><br><span class="line">        <span class="string">'Source'</span>, <span class="string">'Destination'</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line"><span class="comment"># Print the summary</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    print(<span class="string">"Time period %i:"</span> % (i+<span class="number">1</span>), nx.info(subgraph[i]))</span><br></pre></td></tr></table></figure><pre><code>Time period 1: Graph with 781 nodes and 5873 edges
Time period 2: Graph with 771 nodes and 5908 edges
Time period 3: Graph with 788 nodes and 6656 edges
Time period 4: Graph with 754 nodes and 5660 edges
Time period 5: Graph with 820 nodes and 6221 edges
Time period 6: Graph with 848 nodes and 7620 edges
</code></pre><p><img src="/" class="lazyload" data-src="/images/link-predictions/link-predictions_12_0.png" alt=""></p><h2 id="Centrality-Analyses">Centrality Analyses</h2><p>Centrality seeks to answer the question of which node is the most important. To achieve this, we can use a multitude of mathematical definitions of how “central” a node is. In this project, we focus on four measures of centrality:</p><ol><li><strong>Degree</strong></li></ol><p>The most important node would be the one with the most edges. Simple and intuitive.<br>Degree centrality of a node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">x</span></span></span></span> is defined as $$\sum_{y \in V} \frac{1}{d(x,y)}$$</p><ol start="2"><li><strong>Closeness</strong></li></ol><p>By measuring the average distance of a node to all other nodes, the cardinal node is determined to be the one closest to everybody.<br>The closeness of a node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">x</span></span></span></span> is defined as $$\frac{\sum_{y \in V} d(x,y)}{|V|}$$</p><ol start="3"><li><strong>Betweenness</strong></li></ol><p>The betweenness centrality is a measure of how often a node appears “between” two others. Nodes with a high betweenness centrality are important as they can control the flow of information through a graph to the greatest extent. In order to formally define this, if <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">s</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span></span></span></span> are nodes, we define <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>s</mi><mi>t</mi></mrow></msub><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sigma_{st}(v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mclose">)</span></span></span></span> to be the number of shortest paths from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">s</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.61508em;vertical-align:0"></span><span class="mord mathnormal">t</span></span></span></span> that pass through <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span></span></span></span>. Furthermore, we let <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>σ</mi><mrow><mi>s</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\sigma_{st}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.58056em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> to be the total number of those shortest paths. We how state that the betweenness centrality of the node <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal" style="margin-right:.03588em">v</span></span></span></span> is defined as</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>g</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>s</mi><mo mathvariant="normal">≠</mo><mi>t</mi><mo mathvariant="normal">≠</mo><mi>v</mi></mrow></munder><mfrac><mrow><msub><mi>σ</mi><mrow><mi>s</mi><mi>t</mi></mrow></msub><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><msub><mi>σ</mi><mrow><mi>s</mi><mi>t</mi></mrow></msub></mfrac></mrow><annotation encoding="application/x-tex">g(v) = \sum_{s \neq t \neq v}\frac{\sigma_{st}(v)}{\sigma_{st}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.03588em">g</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2777777777777778em"></span></span><span class="base"><span class="strut" style="height:2.865221em;vertical-align:-1.438221em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.050005em"><span style="top:-1.8478869999999998em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="inner"><span class="mrel mtight"></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight">t</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height:.8888799999999999em;vertical-align:-.19444em"></span><span class="inner"><span class="mrel mtight"></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight" style="margin-right:.03588em">v</span></span></span></span><span style="top:-3.0500049999999996em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.438221em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em"><span style="top:-2.3139999999999996em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.2805559999999999em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.8360000000000001em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><ol start="4"><li><strong>Eigenvector</strong></li></ol><p>We do not go into the explanation for why this method is followed however, we state it here. The largest eigenvalue of the adjacency matrix is computed and the eigenvector centrality of a node is the corresponding position in that eigenvalue’s eigenvector. This means that if our vertices are <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>v</mi><mn>1</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msub><mi>v</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(v_1,...,v_n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.30110799999999993em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">v</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.151392em"><span style="top:-2.5500000000000003em;margin-left:-.03588em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>, the vector of eigenvalue centralities <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">x</span></span></span></span> satisfies $$Ax = \lambda x$$ where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.68333em;vertical-align:0"></span><span class="mord mathnormal">A</span></span></span></span> is the adjacency matrix and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.69444em;vertical-align:0"></span><span class="mord mathnormal">λ</span></span></span></span> is the largest eigenvalue.</p><p>For all the centrality measures we plot the entire graph such the size of its nodes corresponds to their centrality.</p><p><img src="/" class="lazyload" data-src="/images/link-predictions/link-predictions_14_0.png" alt=""></p><h2 id="Link-Prediction">Link Prediction</h2><p>Now we shall endeavour to predict the links.<br>We will be doing it in a simple manner: remove a sample of links, and calculate the model accuracy in predicting the missing links.</p><p>This project utilises <a href="https://snap.stanford.edu/node2vec/" target="_blank" rel="noopener">Node2Vec</a>, an algorithm that utilises second order random walks. A <strong>random walk</strong> is when, starting at a particular node, we pick an edge that is incident at that node and then “walk” along it to the next node. Effectively, we choose a random path in the graph with one of the end nodes being the starting node in the graph. In a second order random walk, the algorithm trains a neural network to predict what will happen next depending on the occurrence of other nodes. This network then influences the probability that a node will be selected in a random walk based on this.</p><p>Given a graph, Node2Vec creates a lower-dimensional representation of it referred to as an <strong>embedding</strong>. For our prediction task, instead of training the models on the entire adjacency matrix of the graph, we create an embedding of our the network that captures the most of its structure while reducing the number of dimensions. These embeddings later serve us as the input to the standard machine learning algorithms. We test the Node2Vec embeddings on four classifiers:</p><p><strong>Logistic Regression</strong>, this is the simplest binary linear classifier. Logistic regression is an extension of the linear regression model for classification problems.</p><p><strong>Support Vector Classifier</strong>, the objective of the support vector machine algorithm is to find a hyperplane in an <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span>-dimensional space (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">p</span></span></span></span> — the number of features) that distinctly classifies the data points. To separate the two classes of data points, there are many possible hyperplanes that could be chosen. The goal is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes.</p><p><strong>Gradient Boosting</strong> is when we use multiple functions to learn the main quantity in question. Each of these are referred to as “weak learners” and their combination constitutes the overall behaviour of the predctions of the model. This approach typically outperforms simple random forest classification and, in the case of sklearn, the weak learners are in fact decision trees.</p><p><strong>MLP Classifier</strong> is a multilayer perceptron classfier and uses stochastic gradient descent to optimise the log-loss function. This differs from a logistic regression as there can be hidden layers that give more parameters, thereby allowing the model to use more complex shapes when fitting the model. In addition stochastic gradient descent is a more sophisticated version of gradient descent that is faster for large data sets and is helpful where there are large redundancies in the data.</p><h3 id="Construct-splits-of-the-input-data">Construct splits of the input data</h3><p>We need to be carful how to split our data intro training, validation and test sets in order to avoid <strong>data leakage</strong>.</p><div class="note error"><p><strong>Data leakage</strong> happens when the training data contains information about the target, but similar data will not be available when the model is used for prediction. This leads to high performance on the training set, but the model will perform poorly in production.</p></div><p>We make use of the <code>EdgeSplitter</code> from the <a href="https://stellargraph.readthedocs.io/en/stable/" target="_blank" rel="noopener">StellarGraph</a> Python package and the standard <code>train_test_split</code> function from <a href="https://scikit-learn.org/stable/" target="_blank" rel="noopener">scikit-learn</a> for creating the following subsets of the original data:</p><ul><li>A <strong>Train Graph</strong> for computing node embeddings (<code>graph_train</code>)</li><li>A training set of positive and negative edges that weren’t used for computing node embeddings for training classifiers (<code>edges_train</code>)</li><li>A validation set for choosing the best classifier, i.e. a set of positive and negative edges that weren’t used for computing node embeddings or training the classifier (<code>edges_val</code>)</li><li>A <strong>Test Graph</strong> to compute test node embeddings (<code>graph_test</code>), and a test set (<code>edges_test</code>) of positive and negative edges not used for neither computing the test node embeddings or for classifier training or model selection</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> stellargraph.data <span class="keyword">import</span> EdgeSplitter</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">sg_graph = sg.StellarGraph.from_networkx(e_graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define an edge splitter on the full graph:</span></span><br><span class="line">edge_splitter_test = EdgeSplitter(sg_graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Randomly sample a fraction p=0.1 of all positive links</span></span><br><span class="line"><span class="comment"># and same number of negative links</span></span><br><span class="line">graph_test, edges_test, labels_test = edge_splitter_test.train_test_split(</span><br><span class="line">    p=<span class="number">0.1</span>, method=<span class="string">"global"</span>, seed=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the training subset from within the test graph</span></span><br><span class="line">edge_splitter_train = EdgeSplitter(graph_test, sg_graph)</span><br><span class="line">graph_train, edges, labels = edge_splitter_train.train_test_split(</span><br><span class="line">    p=<span class="number">0.1</span>, method=<span class="string">"global"</span>, seed=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line">(edges_train, edges_val, labels_train, labels_val) \</span><br><span class="line">= train_test_split(edges, labels, train_size=<span class="number">0.75</span>, test_size=<span class="number">0.25</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>Number of Examples</th><th>Hidden from</th><th>Picked from</th><th>Use</th></tr><tr><th>Split</th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><th>Training</th><td>2167</td><td>Train Graph</td><td>Test Graph</td><td>Train the Link Classifier</td></tr><tr><th>Validation</th><td>723</td><td>Train Graph</td><td>Test Graph</td><td>Select the best Link Classifier model</td></tr><tr><th>Test</th><td>3212</td><td>Test Graph</td><td>Full Graph</td><td>Evaluate the best Link Classifier</td></tr></tbody></table><h3 id="Train-and-validate-the-link-prediction-model">Train and validate the link prediction model</h3><p>There are a few steps involved in using the Node2Vec model to perform link prediction:</p><ol><li>Generate features for the positive and negative edge samples by calculating a <em>distance</em> between the embeddings of the source and target nodes of each sampled edge. (Here we will use the L1 distance)</li><li>Given the features, we train four binary classifiers to predict whether an edge between two nodes should exist or not.</li><li>Evaluate the performance of the link classifier for each of the four classifier on the validation set with node embeddings calculated on the Train Graph, and select the best classifier.</li><li>The best classifier is finally used to calculate scores on the test data with node embeddings calculated on the Test Graph.</li></ol><p>The number of positive and negative examples in each set used for training, validating and testing is set to be the same. Therefore, we can use accuracy as the defualt model selection metric.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> stellargraph.data <span class="keyword">import</span> BiasedRandomWalk</span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"></span><br><span class="line">dimensions = <span class="number">64</span></span><br><span class="line">num_walks = <span class="number">10</span></span><br><span class="line">walk_length = <span class="number">80</span></span><br><span class="line">window_size = <span class="number">10</span></span><br><span class="line">workers = <span class="number">4</span></span><br><span class="line">seed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">embed_graph</span><span class="params">(graph)</span>:</span></span><br><span class="line">    rw = BiasedRandomWalk(graph, seed=seed)</span><br><span class="line">    walks = rw.run(graph.nodes(), n=num_walks, length=walk_length)</span><br><span class="line">    model = Word2Vec(</span><br><span class="line">        walks,</span><br><span class="line">        vector_size=dimensions,</span><br><span class="line">        window=window_size,</span><br><span class="line">        min_count=<span class="number">0</span>,</span><br><span class="line">        sg=<span class="number">1</span>,</span><br><span class="line">        workers=workers,</span><br><span class="line">        seed=seed</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_embedding</span><span class="params">(u)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> model.wv[u]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> get_embedding</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="keyword">from</span> sklearn.neural_network <span class="keyword">import</span> MLPClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_features</span><span class="params">(edges, get_embedding)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [</span><br><span class="line">        np.abs(get_embedding(src) - get_embedding(dst)) </span><br><span class="line">        <span class="keyword">for</span> src, dst <span class="keyword">in</span> edges</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(mod_name, edges, labels, get_embedding)</span>:</span></span><br><span class="line">    clf = classifier(mod_name)</span><br><span class="line">    features = get_features(edges, get_embedding)</span><br><span class="line">    clf.fit(features, labels)</span><br><span class="line">    <span class="keyword">return</span> clf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifier</span><span class="params">(mod_name, max_iter=<span class="number">2000</span>, seed=<span class="number">0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> mod_name == <span class="string">"Logistic Regression"</span>:</span><br><span class="line">        clf = LogisticRegression(max_iter=max_iter, random_state=seed)</span><br><span class="line">    <span class="keyword">elif</span> mod_name == <span class="string">"SVC"</span>:</span><br><span class="line">        clf = SVC(max_iter=max_iter, random_state=seed)</span><br><span class="line">    <span class="keyword">elif</span> mod_name == <span class="string">"Gradient Boosting"</span>:</span><br><span class="line">        clf = GradientBoostingClassifier(random_state=seed)</span><br><span class="line">    <span class="keyword">elif</span> mod_name == <span class="string">"MLP"</span>:</span><br><span class="line">        clf = MLPClassifier(max_iter=max_iter, random_state=seed)</span><br><span class="line">    <span class="keyword">return</span> Pipeline(steps=[(<span class="string">"sc"</span>, StandardScaler()), (<span class="string">"clf"</span>, clf)])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(clf, test_edges, test_labels, get_embedding)</span>:</span></span><br><span class="line">    test_features = get_features(test_edges, get_embedding)</span><br><span class="line">    predicted = clf.predict(test_features)</span><br><span class="line">    score = accuracy_score(test_labels, predicted) * <span class="number">100</span></span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>Accuracy</th></tr></thead><tbody><tr><th>Logistic Regression</th><td>81.88</td></tr><tr><th>SVC</th><td>82.30</td></tr><tr><th>Gradient Boosting</th><td>80.08</td></tr><tr><th>MLP</th><td>78.01</td></tr></tbody></table><p>SVC performs the best, we will use it for our final classifier.</p><h3 id="Evaluate-the-best-model-using-the-test-set">Evaluate the best model using the test set</h3><p>Now that we’ve trained and selected our best model, we use a test set of embeddings and calculate a final evaluation score. The Node2Vec combined with SVC achieves 79.67% accuracy on the test set.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_embedding = embed_graph(graph_test)</span><br><span class="line">test_score = evaluate(models[<span class="string">'SVC'</span>], edges_test, labels_test, test_embedding)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Test Accuracy of the SVC classifier: &#123;:.2f&#125;%"</span>.format(test_score))</span><br></pre></td></tr></table></figure><pre><code>Test Accuracy of the SVC classifier: 79.67%
</code></pre><h1>Further Research</h1><p>It is worth noting that since this email dataset is temporal, it is certainly possible to use the past (a subset of data from an earlier time period) to predict the future, rather than taking just taking out a random sample of edges. In such case, the link prediction task can be treated as like a time series problem. We would be interested in trying out the approach presented by <a href="https://dro.dur.ac.uk/29741/1/29741.pdf?DDC116+DDD4+wfhf31" target="_blank" rel="noopener">Bonner et al. (2019)</a>.</p><p>In addition, the email dataset does not contain features of the nodes themselves, while the G+ one does (features such as occupation, university attended, etc.). For the G+ dataset, one can make advantage of knowing the characteristics of each person, thus the similarities between people, not only the graph structure itself. This would potentially allow for better prediction accuracy and for identifying factors that may be significant in forming of friendships, further informing the results.</p><h1>Conclusion</h1><p>In conclusion, this article sought to explain how we can make predictions using graph-type data set. We applied ML models for link prediction, achieving a decent accuracy score of near 80%. While attributes of friends have not been scrutinised, literature of university students points to the same discipline of study (<a href="https://doi.org/10.1016/j.comcom.2015.07.007" target="_blank" rel="noopener">Ding et al. 2015</a>) and similar physical characteristics such as age and gender (<a href="https://doi.org/10.1016/j.ins.2018.06.029" target="_blank" rel="noopener">Wang et al. 2018</a>) - factors which would have affected the common friends number in the first place. But predictions only point to doors, one has many others to knock on, and the onus on them to open.</p></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Authors: </span><span class="post-copyright-info"><a class="post-meta__categories" href="https://www.linkedin.com/in/kah-long-ng-6b10b81b9/" target="_blank" rel="noopener">Kah Long Ng</a><span>, </span><a class="post-meta__categories" href="https://www.linkedin.com/in/peter-hyland-53a2951ba/" target="_blank" rel="noopener">Peter Hyland</a></span></div><div class="post-copyright__author"><span class="post-copyright-meta">Editor: </span><span class="post-copyright-info"><a href="https://www.linkedin.com/in/katarzyna-kobalczyk/" target="_blank" rel="noopener">Katarzyna Kobalczyk</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Permalink: </span><span class="post-copyright-info"><a href="https://research.wdss.io/link-predictions/">https://research.wdss.io/link-predictions/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless otherwise specified.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/machine-learning/">machine learning</a><a class="post-meta__tags" href="/tags/predictions/">predictions</a><a class="post-meta__tags" href="/tags/graph-neural-networks/">graph neural networks</a></div><div class="post_share"><div class="social-share" data-image="/banners/social-network.jpg" data-sites="facebook,twitter,linkedin"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/sales-forecasting-challenge/"><img class="next_cover lazyload" data-src="/banners/time-series.png" onerror='onerror=null,src="/img/404.jpg"'><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Store Sales - Time Series Forecasting Challenge</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommended</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/chemical-properties/" title="Predicting aqueous solubility with neural networks"><img class="relatedPosts_cover lazyload" data-src="/banners/chemistry-lab.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2021-10-19</div><div class="relatedPosts_title">Predicting aqueous solubility with neural networks</div></div></a></div><div class="relatedPosts_item"><a href="/sales-forecasting-challenge/" title="Store Sales - Time Series Forecasting Challenge"><img class="relatedPosts_cover lazyload" data-src="/banners/time-series.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2022-02-12</div><div class="relatedPosts_title">Store Sales - Time Series Forecasting Challenge</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> Comment</span></div><div id="disqus_thread"></div><script>var disqus_config=function(){this.page.url="https://research.wdss.io/link-predictions/",this.page.identifier="link-predictions/",this.page.title="Graph Neural Networks for link predictions"};!function(){var e=document,t=e.createElement("script");t.src="https://wdss-research-blog.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)}()</script><script>function getDisqusCount(){var s=document,t=s.createElement("script");t.src="https://wdss-research-blog.disqus.com/count.js",t.id="dsq-count-scr",(s.head||s.body).appendChild(t)}window.addEventListener("load",getDisqusCount,!1)</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Warwick Data Science</div><div class="framework-info"><span>Powered By </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="Comments"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49b1f5">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function(){$("span.katex-display").wrap('<div class="katex-wrap"></div>')})</script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async></script><script src="/js/search/local-search.js"></script></body></html>