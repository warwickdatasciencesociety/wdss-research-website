<!DOCTYPE html><html lang="en" data-theme="light"><head><script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">window.dojoRequire(["mojo/signup-forms/Loader"],function(o){o.start({baseUrl:"mc.us4.list-manage.com",uuid:"1fd8b3cd2ba70f51528f758b7",lid:"0a5bf38afd",uniqueMethods:!0})})</script><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Gibrat's Law: The Central Limit Theorem's Forgotten Twin | Research @ WDSS</title><meta name="description" content="Hiding in the shadow of the central limit theorm is a lesser-know, but still fascinating aspect of statistics. Read this post to what this is and how we can use it."><meta name="keywords" content="lesson,normal-distribution"><meta name="author" content="Warwick Data Science"><meta name="copyright" content="Warwick Data Science"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Gibrat's Law: The Central Limit Theorem's Forgotten Twin"><meta name="twitter:description" content="Hiding in the shadow of the central limit theorm is a lesser-know, but still fascinating aspect of statistics. Read this post to what this is and how we can use it."><meta name="twitter:image" content="https://research.wdss.io/banners/gibrats-law.jpg"><meta property="og:type" content="article"><meta property="og:title" content="Gibrat's Law: The Central Limit Theorem's Forgotten Twin"><meta property="og:url" content="https://research.wdss.io/gibrats-law/"><meta property="og:site_name" content="Research @ WDSS"><meta property="og:description" content="Hiding in the shadow of the central limit theorm is a lesser-know, but still fascinating aspect of statistics. Read this post to what this is and how we can use it."><meta property="og:image" content="https://research.wdss.io/banners/gibrats-law.jpg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode="1",t=Cookies.get("theme");if("1"==autoChangeMode){var isDarkMode=window.matchMedia("(prefers-color-scheme: dark)").matches,isLightMode=window.matchMedia("(prefers-color-scheme: light)").matches,isNotSpecified=window.matchMedia("(prefers-color-scheme: no-preference)").matches,hasNoSupport=!isDarkMode&&!isLightMode&&!isNotSpecified;if(void 0===t){if(isLightMode)activateLightMode();else if(isDarkMode)activateDarkMode();else if(isNotSpecified||hasNoSupport){console.log("You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.");var now=new Date,hour=now.getHours(),isNight=hour<6||18<=hour;isNight?activateDarkMode():activateLightMode()}}else"light"==t?activateLightMode():activateDarkMode()}else"2"==autoChangeMode?(isNight=(hour=(now=new Date).getHours())<6||18<=hour,void 0===t?isNight?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode()):"dark"==t?activateDarkMode():"light"==t&&activateLightMode();function activateDarkMode(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#000")}function activateLightMode(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#fff")}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://research.wdss.io/gibrats-law/"><link rel="prev" title="What Factors Actually Affect Your Grades?" href="https://research.wdss.io/school-success/"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><script>(adsbygoogle=window.adsbygoogle||[]).push({google_ad_client:"4718922828481704",enable_page_level_ads:"true"})</script><script data-ad-client="ca-pub-4718922828481704" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"We didn't find any results for: ${query}"}},translate:void 0,copy:{success:"Copied successfully",error:"Copy failed",noSupport:"Not supported by browser"},bookmark:{message_prev:"Press",message_next:"to bookmark this page"},runtime_unit:"days",runtime:!0,copyright:void 0,ClickShowText:void 0,medium_zoom:!1,fancybox:!0,Snackbar:{bookmark:{message_prev:"Press",message_next:"to bookmark this page"},chs_to_cht:"Traditional Chinese Activated Manually",cht_to_chs:"Simplified Chinese Activated Manually",day_to_night:"Dark Mode Activated Manually",night_to_day:"Light Mode Activated Manually",bgLight:"#49b1f5",bgDark:"#2d3035",position:"bottom-left"},baiduPush:!1,highlightCopy:!0,highlightLang:!0,highlightShrink:"false",isFontAwesomeV5:!1,isPhotoFigcaption:!1}</script><script>var GLOBAL_CONFIG_SITE={isPost:!0,isHome:!1,isSidebar:!0}</script><noscript><style>#page-header{opacity:1}.justified-gallery img{opacity:1}</style></noscript><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="Research @ WDSS" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">23</div></a></div></div><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">37</div></a></div></div><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">23</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">Contents</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Testing-and-Tediosity"><span class="toc-number">1.1.</span> <span class="toc-text">Testing and Tediosity</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Background"><span class="toc-number">2.</span> <span class="toc-text">Background</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Central-Limit-Theorem"><span class="toc-number">2.1.</span> <span class="toc-text">The Central Limit Theorem</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Importance-of-the-CLT"><span class="toc-number">2.2.</span> <span class="toc-text">The Importance of the CLT</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#From-Sums-to-Products"><span class="toc-number">3.</span> <span class="toc-text">From Sums to Products</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Verifying-the-Law"><span class="toc-number">4.</span> <span class="toc-text">Verifying the Law</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Sourcing-Data"><span class="toc-number">4.1.</span> <span class="toc-text">Sourcing Data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Visualizing-the-Results"><span class="toc-number">4.2.</span> <span class="toc-text">Visualizing the Results</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image:url(/banners/gibrats-law.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Research @ WDSS</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Gibrat's Law: The Central Limit Theorem's Forgotten Twin</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="Created 2020-04-10 00:00:00"><i class="fa fa-calendar" aria-hidden="true"></i> Created 2020-04-10</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="Updated 2020-05-08 00:00:00"><i class="fa fa-history" aria-hidden="true"></i> Updated 2020-05-08</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-user post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="https://www.linkedin.com/in/tim-hargreaves/" target="_blank" rel="noopener">Tim Hargreaves</a></span><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Meta/">Meta</a><span>, </span><a class="post-meta__categories" href="/categories/Mathematics/">Mathematics</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Mathematics/Statistics/">Statistics</a></span></div><div class="meta-secondline"><span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>Word count:</span><span class="word-count">2.4k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>Reading time: 15 min</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span></span><span class="post-meta-commentcount"><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>Comments:</span><span class="disqus-comment-count comment-count"><a href="https://research.wdss.io/gibrats-law/#disqus_thread"></a></span></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><div class="note info"><p><strong>Accessing Post Source</strong><br>We are still working on getting this site set up, so source code for this post is not yet available. Check back soon and you’ll be able to find it linked here.</p></div><p>Testing, testing. One, two, three. Can everyone hear me alright?</p><p>Wonderful. Hello and welcome to the Warwick Data Science Society Research Blog. It’s so nice to see you.</p><h2 id="Introduction">Introduction</h2><h3 id="Testing-and-Tediosity">Testing and Tediosity</h3><p>Testing is boring. Everyone knows that they <em>should</em> test the solutions they produce, yet reality often fails to live up to this ideal. We check a few obvious things, run through the logic in our head, and convince ourselves that nothing could ever go wrong…and then it does just that.</p><p>Sometimes this is okay. For small, individual projects, it’s not the end of the world if your code base comes collapsing down on you; a few hours of bodging and everything should be stable again (all be it with code now so messy that you’d want to consider cryongenics). For larger projects, and especially those of collaborative nature, this just won’t do.</p><p>That is a long way to say, this post is a test, but hopefully not a boring one. To ensure that the testing of this site is performed thoroughly, I decided to write this post to ensure that everything is behaving as expected. I hope it can also act as a template for other keen researchers—whether they are currently a member of WDSS or merely interested in getting involved—to contribute their own work.</p><p>The philosophy of this post is to write about a topic that is actually (well, hopefully) of some interest to people, and do so in a natural way. None of this testing through enumerating corner-cases; let’s use the site for what it’s made for in practice and share some interesting insights along the way.</p><p>With that in mind, I wish to introduce to you: Gibrat’s law. Don’t be disheartened if you haven’t come across this term before,—most haven’t. This is likely because the rule is overshadowed by it’s far more infamous twin, the central limit theorem. If you’ve not come across this second term either, don’t fret. You may want to watch <a href="https://www.youtube.com/watch?v=JNm3M9cqWyc" target="_blank" rel="noopener">this short video</a> by <a href="https://www.khanacademy.org/" target="_blank" rel="noopener">Khan Academy</a> as a preliminary, but we’ll introduce both of these ideas either way.</p><div class="note info"><p>As a matter of fact, the <a href="https://en.wikipedia.org/wiki/Gibrat%27s_law" target="_blank" rel="noopener">Wikipedia article for Gibrat’s Law</a> is only made up of a few paragraphs with the link to the law’s creator, Robert Gibrat, directing you to a yet non-existant page. We seem to be diving head first into the rabbit hole today.</p></div><h2 id="Background">Background</h2><div class="note warning"><p>If you are already familiar with central limit theorem, you may wish to skip to the <a href="#from-sums-to-products">next section</a>.</p></div><h3 id="The-Central-Limit-Theorem">The Central Limit Theorem</h3><p>We’ll start with the central limit theorem. There are many ways of explaining or defining this phenomenon, each striking a subtle balance between statistical rigor and clarity of explanation. We will favor the latter, ensuring to remember that we should keep it too ourselves if we wish to avoid the disapproving gaze of the pure probability theorists.</p><p>This simplified description goes as follows:</p><ul><li>Consider a sequence of independent random variables</li><li>Take the sum of these values</li><li>Regardless of whether the original variables were normally distributed, the distribution of this sum will tend towards a <a href="https://www.mathsisfun.com/data/standard-normal-distribution.html" target="_blank" rel="noopener">normal distribution</a> as the number of variables increases</li></ul><p>To clarify this notion, let’s look an example. One of the simplest would be an experiment involving tossing multiple fair coins. We consider each coin flip to be an independent random variable taking value zero if the result is tails, and likewise one for heads. We can then say that the total number of heads is the sum of these random variables. It would follow from the central limit theorem that the total number of heads should therefore tend to a normal distribution as the number of total coin tosses gets large. Let’s simulate this experiment for different numbers of coins and see this process in action.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_18_0.png" alt=""></p><p>Just as we expected, the more coins we toss, the closer the resulting distribution of heads resembles the classic bell shape of the normal distribution. Indeed, once we use around one hundred or more tosses, we can almost model the number of heads as a continuous variable.</p><h3 id="The-Importance-of-the-CLT">The Importance of the CLT</h3><p>It’s all well and good that the theory works, but why should we care?</p><p>The real power of the central limit theorem presents itself when we want to perform statistical analysis or tests on unfriendly distributions. The normal distribution has some incredibly delightful properties and has been studied in great extent, so working with it is often straightforward. On the other hand, there are many distributions which are not so cooperative, and that’s even assuming we know the distribution of whatever we are trying to model. Thankfully, the central limit theorem allows us to circumvent these issues by assuring us that as long as our process can be modeled as the sum of independent random variables (which is a surprisingly common property), we can approximate its distribution as normal and apply all of the standard techniques we know and love.</p><p>For example, the number of visitors to a website in a given time period is unlikely to have an underlying normal distribution governing the process. This could make it difficult to analyze data related to this, however the central limit theorem offers a workaround. The rough conceptual notion behind this approach is to divide our time period up into smaller and smaller intervals and consider how many people visit the website in each of those. We can assume that these are reasonably independent and so our total visitor count becomes the sum of many independent random variables and so the central limit theorem holds. A small caveat of this specific result is that we require the number of visitors to the site in the time period to be reasonably large (&gt;20 visitors is typically fine), but as long as this holds, we can perform analysis just as if our data was normally distributed.</p><div class="note success"><p>We can even go one step further. Since translating or scaling a normal distribution does not change its normality, it is possible to approximate many situations using the standard normal distrubtion (mean 0, variance 1) by applying appropriate transformations. This makes our lives even simpler and offers some elegance in the process.</p></div><h2 id="From-Sums-to-Products">From Sums to Products</h2><p>This leads us nicely onto Gibrat’s law. In our rough definition of the central limit theorem above, we described taking numerous independent random variables and computing their sum. Gibrat’s law begins in a similar vein but goes on to consider the product of these values instead. Because of this alteration, we can no longer expect the aggregation to approach a normal distribution as the number of variables grows large. Instead we tend towards a related distribution—the log-normal distribution.</p><p>As the name eludes to, a random variable following log-normal distribution can be defined by its logarithm being normally distributed. The converse of this framing is that whenever we take a normal random variable and take its exponential, the result will follow a log-normal distribution. Because of this, a log-normal random variable only takes strictly positive values with a density curve along the lines of the following.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_28_0.png" alt=""></p><p>Just as with our coin-tossing experiment for the central limit theorem, we can validate our belief in Gibrat’s law using another simulation. We’ll introduce an explicit example of Gibrat’s law in the final section of the post and for now look an a more esoteric example. In particular, we will consider numerous independent random variables, uniformly-distributed on the interval <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0.5</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0.5, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mord">.</span><span class="mord">5</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.16666666666666666em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>. We then take the product of the first <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">n</span></span></span></span> these variables and look at the probability distribution of this value. Using Gibrat’s law we would expect this product to approach a log-normal as <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.43056em;vertical-align:0"></span><span class="mord mathnormal">n</span></span></span></span> becomes large, with a density tending in shape towards the curves shown above. A few simulations shows exactly that.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_30_0.png" alt=""></p><div class="note success"><p>The example shown here is, admittedly, rather abstract. Despite this, it is still simple to frame it in terms of a real world problem (though perhaps not one of upmost importance). For example, we could imagine the product of independent uniform random variables modeling the process of repeatedly cutting a piece of string at a randomly chosen point along its length and retaining the longer part.</p></div><p>It is worth noting that just as there is no one normal distribution, but rather many of various shapes and sizes, parameterized by their mean (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.19444em"></span><span class="mord mathnormal">μ</span></span></span></span>) and variance (<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8141079999999999em;vertical-align:0"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141079999999999em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>), the same is true for the log-normal distribution. In fact, we parameterize a log-normal distribution not by its own mean and variance, but by the mean and variance of the resulting normal distribution we obtain when taking logarithms.</p><p>This relationship between the two distributions offers us much of the same power the central limit theorem displays for Gibrat’s law too. Yes, taking the product of the independent random variables in its definition doesn’t give us the normal distribution we so desire directly, but with a simple logarithmic transformation we can get there. Further, because taking the logarithm of a random variable is a simple transformation with some desirable properties, we are able to utilize many of the tools we have developed for manipulating and analyzing the normal distribution with log-normal distribution. This in turn makes Gibrat’s law an incredibly powerful tool for simplifying statistical analysis. One question remains though: when does it hold? What sort of scenarios can be modeled as a product of independent random variables? This brings us neatly to the final section of this post in which we will look into just that, and confirm Gibrat’s law in action.</p><h2 id="Verifying-the-Law">Verifying the Law</h2><p>So far we’ve discussed some interesting ideas, but I think it’s time to pull things back from the land of statistical theory into the real world. Where would we expect to find Gibrat’s law in our lives?</p><p>The key insight needed to answer this question is to understand the underlying mechanism of Gibrat’s law; it’s all above the multiplication of random variables. Specifically, we take the previous product and multiply it by some new random amount. Another way of looking at this is that these random variables represent the growth rate of some quantity. Now, this is not a fixed growth rate as you would have say with interest rates or nuclear decay, but rather a stochastic growth rate.</p><p>To simplify this notion, all we are looking for is systems that evolve by a growth rate proportional to their current size with some added variation captured by the random nature of the variables. An example of such a system (and incidentally the original inspiration for the law) is that of modeling the growth of a firm. In a simple model, we can ignore the impacts of overarching market changes and catastrophic economic events and instead suggest that the growth of a company is roughly proportional to its current size with some added noise. Obviously, this model is primitive and its assumptions do not hold exactly, but it is close enough to believe that the distribution of the size of firms would indeed be log-normally distributed.</p><p>Another example could be the distribution of the population sizes for various countries or cities. There are clear troubles with modeling such a system using Gibrat’s law, but overall it is not unreasonable to suggest that the population growth of a city is largely dependent on its current size, with some added stochasticity. Don’t take my word for it though! Instead, let’s quickly gather some data to verify this result for ourselves.</p><h3 id="Sourcing-Data">Sourcing Data</h3><p>After some searching, I decided that the best data source to investigate the validity of Gibrat’s law for use with population data is <a href="https://en.wikipedia.org/wiki/List_of_cities_in_the_United_Kingdom" target="_blank" rel="noopener">this Wikipedia article</a> containing the populations of all sovereign states and dependencies. I then scraped relevant columns from the main table of this page, resulting in a dataset for which ten randomly chosen rows are shown below.</p><table><thead><tr><th></th><th>City</th><th>Population</th></tr></thead><tbody><tr><th>5</th><td>Manchester</td><td>503127</td></tr><tr><th>24</th><td>Southampton</td><td>236882</td></tr><tr><th>28</th><td>York</td><td>198051</td></tr><tr><th>31</th><td>Chelmsford</td><td>168310</td></tr><tr><th>32</th><td>Dundee</td><td>153990</td></tr><tr><th>51</th><td>Bath</td><td>88859</td></tr><tr><th>53</th><td>Hereford</td><td>58896</td></tr><tr><th>56</th><td>Stirling</td><td>34790</td></tr><tr><th>57</th><td>Lichfield</td><td>32219</td></tr><tr><th>66</th><td>London</td><td>7375</td></tr></tbody></table><h3 id="Visualizing-the-Results">Visualizing the Results</h3><p>We can now plot a histogram of the populations for these cities. On top of this, we overlay a log-normal distribution with parameters chosen to best fit (using maximum likelihood estimation) to see how well the densities match.</p><p><img src="/" class="lazyload" data-src="/images/gibrats-law/gibrats-law_44_0.png" alt=""></p><p>Now, before you say anything, I know. It’s not perfect. But, I hope we can agree that there is definitely <em>something</em> there. It’s also quite easy to explain why the match isn’t exact. For a start, we only had data for 69 cities so it’s no surprise that the histogram is so jagged. On top of this, city populations is one of the more difficult applications of Gibrat’s law due to the many factors that influence their size that aim to violate the assumptions of the rule.</p><p>Despite these shortcomings, it is clear that Gibrat’s law has value to it either as a conceptual or statistical tool. It should certainly be the case that the validity of the law in any particular scenario should be tested thoroughly before resting too heavy on the results, but as a tool to guide you in the right direction, it is is invaluable.</p><p>As eluded to above, the example of population data is more difficult than most applications of Gibrat’s law due to the numerous and influential externalities. I didn’t want to shy away from this case, especially when it is an example that has clear real-world implications for modeling. It therefore follows that in many more simplistic and controlled cases, Gibrat’s law shines even brighter. For example, it has been of great benefit in my work at AstraZeneca in forming suitable priors for energy distributions in statistical models. Without knowledge of this law it may have taken me more time to discover that the log-normal distribution was a natural and accurate model for these quanta.</p><p>If anything, this post does not offer anything of immediate practical use. That is not to say however that there isn’t an important message. That is, remember Gibrat’s law—it’s there more than you think, and your awareness of it is vital for optimum efficiency in your statistical work. I hope you found this post of some insight, and I look forward to sharing more ideas and research as this blog developments.</p></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="https://www.linkedin.com/in/tim-hargreaves/" target="_blank" rel="noopener">Tim Hargreaves</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Permalink: </span><span class="post-copyright-info"><a href="https://research.wdss.io/gibrats-law/">https://research.wdss.io/gibrats-law/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless otherwise specified.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/lesson/">lesson</a><a class="post-meta__tags" href="/tags/normal-distribution/">normal-distribution</a></div><div class="post_share"><div class="social-share" data-image="/banners/voting.png" data-sites="facebook,twitter,linkedin"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/school-success/"><img class="prev_cover lazyload" data-src="/banners/school-success.jpg" onerror='onerror=null,src="/img/404.jpg"'><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">What Factors Actually Affect Your Grades?</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> Recommended</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/money-for-nothing/" title="Money for Nothing: An Arbitrage Paradox"><img class="relatedPosts_cover lazyload" data-src="/banners/money-for-nothing.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-07-23</div><div class="relatedPosts_title">Money for Nothing: An Arbitrage Paradox</div></div></a></div><div class="relatedPosts_item"><a href="/polish-countdown/" title="A Polish Approach to Countdown"><img class="relatedPosts_cover lazyload" data-src="/banners/polish-countdown.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-12-09</div><div class="relatedPosts_title">A Polish Approach to Countdown</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> Comment</span></div><div id="disqus_thread"></div><script>var disqus_config=function(){this.page.url="https://research.wdss.io/gibrats-law/",this.page.identifier="gibrats-law/",this.page.title="Gibrat's Law: The Central Limit Theorem's Forgotten Twin"};!function(){var t=document,e=t.createElement("script");e.src="https://wdss-research-blog.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><script>function getDisqusCount(){var s=document,t=s.createElement("script");t.src="https://wdss-research-blog.disqus.com/count.js",t.id="dsq-count-scr",(s.head||s.body).appendChild(t)}window.addEventListener("load",getDisqusCount,!1)</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Warwick Data Science</div><div class="framework-info"><span>Powered By </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="Read Mode"></i><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><i class="darkmode fa fa-moon-o" id="darkmode" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="Comments"><i class="scroll_to_comment fa fa-comments"></i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="Table of Contents" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49b1f5">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function(){$("span.katex-display").wrap('<div class="katex-wrap"></div>')})</script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async></script><script src="/js/search/local-search.js"></script></body></html>